{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xbart import XBART\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "import csv\n",
    "\n",
    "\n",
    "######################################\n",
    "# Compare xbart, xbart-gp, jackknife+ with XBART & XBART-GP, CV+ with xbart & rf.\n",
    "# test set: N(0, 2) with 100 interior points and 100 exterior points\n",
    "######################################\n",
    "note = 'simulation studies on update_gp branch, theta = 0.1, tau = var(y)/L'\n",
    "\n",
    "seed = 98765\n",
    "np.random.seed(seed)\n",
    "\n",
    "TOL = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "######################################\n",
    "# Define regression algorithm (for all other methods)\n",
    "######################################\n",
    "\n",
    "def leastsq_minL2(X,Y,X1,tol=TOL):\n",
    "    uX,dX,vX = np.linalg.svd(X)\n",
    "    rX = (dX>=dX[0]*tol).sum()\n",
    "    betahat = (vX[:rX].T/dX[:rX]).dot(uX[:,:rX].T.dot(Y))\n",
    "    return X1.dot(betahat)\n",
    "\n",
    "def leastsq_ridge(X,Y,X1,ridge_mult=0.001):\n",
    "    lam = ridge_mult * np.linalg.svd(X,compute_uv=False).max()**2\n",
    "    betahat = np.linalg.solve(\\\n",
    "            np.c_[np.ones(X.shape[0]),X].T.dot(np.c_[np.ones(X.shape[0]),X]) \\\n",
    "                              + lam * np.diag(np.r_[0,np.ones(X.shape[1])]),\n",
    "            np.c_[np.ones(X.shape[0]),X].T.dot(Y))\n",
    "    return betahat[0] + X1.dot(betahat[1:])\n",
    "\n",
    "def random_forest(X,Y,X1,ntree=20):\n",
    "    rf = RandomForestRegressor(n_estimators=ntree,criterion='mae').fit(X,Y)\n",
    "    return rf.predict(X1)\n",
    "\n",
    "def neural_net(X,Y,X1):\n",
    "    nnet = MLPRegressor(solver='lbfgs',activation='logistic').fit(X,Y)\n",
    "    return nnet.predict(X1)\n",
    "\n",
    "def check_out_of_range(x1, x_min, x_max):\n",
    "    for i in range(len(x1)):\n",
    "        if x1[i] < x_min[i] or x1[i] > x_max[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "# Define dgp\n",
    "######################################\n",
    "\n",
    "def jacknife_linear(x):\n",
    "    beta = np.random.normal(size=x.shape[1])\n",
    "    beta = beta/np.sqrt((beta**2).sum()) * np.sqrt(SNR)\n",
    "    return x.dot(beta)\n",
    "\n",
    "def linear(x):\n",
    "    d = x.shape[1]\n",
    "    beta = [-2 + 4*(i - 1) / (d-1) for i in range(1, d+1)]\n",
    "    return x.dot(beta)\n",
    "    \n",
    "def single_index(x):\n",
    "    d = x.shape[1]\n",
    "    gamma = [-1.5 + i/3 for i in list(range(0, d))]\n",
    "    a =  np.apply_along_axis(lambda x: sum((x-gamma)**2), 1, x)\n",
    "    f = 10 * np.sqrt(a) + np.sin(5*a)\n",
    "    return f\n",
    "\n",
    "def trig_poly(x):\n",
    "    f = np.apply_along_axis(lambda x: 5 * np.sin(3*x[0]) + 2 * x[1]**2 + 3 * x[2] * x[3], 1, x)\n",
    "    return f\n",
    "\n",
    "def xbart_max(x):\n",
    "    return np.apply_along_axis(lambda x: max(x[0:2]), 1, x)\n",
    "\n",
    "def generate_data(x, dgp):\n",
    "    if dgp == 'linear':\n",
    "        return linear(x)\n",
    "    if dgp == 'single_index':\n",
    "        return single_index(x)\n",
    "    if dgp == 'trig_poly':\n",
    "        return trig_poly(x)\n",
    "    if dgp == 'max':\n",
    "        return xbart_max(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tight-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create csv file: xbart_gp_sim.csv\n",
      "test_scale: 1.5\n",
      "method_names: ['XBART', 'XBART-GP', 'jackknife+ XBART', 'jackknife+ XBART-GP', 'CV+ XBART', 'CV+ XBART_GP']\n",
      "Experiment: simulation studies on update_gp branch, theta = 0.1, tau = var(y)/L\n",
      "dgp = linear\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# simulation\n",
    "n = 200; \n",
    "n1 = 200\n",
    "SNR = 10\n",
    "# ntrial = 50\n",
    "ntrial = 10\n",
    "alpha = 0.1\n",
    "test_scale = 1.5\n",
    "d = 10\n",
    "dgp_list = ['linear', 'single_index', 'trig_poly', 'max']\n",
    "\n",
    "method_names = ['XBART','XBART-GP','jackknife+ XBART','jackknife+ XBART-GP','CV+ XBART', 'CV+ XBART_GP']\n",
    "\n",
    "results = pd.DataFrame(columns = ['itrial','dgp','method','rmse','coverage','width','coverage_type', 'size'])\n",
    "\n",
    "filename = 'xbart_gp_sim.csv'\n",
    "if not exists(filename):\n",
    "    print(\"create csv file: \"+filename)\n",
    "    with open(filename, 'w',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # write the header\n",
    "        writer.writerow(list(results.columns))\n",
    "\n",
    "print('test_scale: '+ str(test_scale))\n",
    "print('method_names: ' + str(method_names))\n",
    "print('Experiment: ' + note)\n",
    "\n",
    "dgp = dgp_list[0]\n",
    "print(\"dgp = \" + str(dgp))\n",
    "\n",
    "X = np.random.normal(size=(n,d))\n",
    "Y = generate_data(X, dgp) + np.random.normal(size=n)\n",
    "\n",
    "# sample test set and distinguish interiors and outliers.\n",
    "X1 = np.random.normal(size=(n1,d), scale = test_scale)\n",
    "X_min = np.apply_along_axis(lambda x: x.min(), 0, X)\n",
    "X_max = np.apply_along_axis(lambda x: x.max(), 0, X)\n",
    "outliers = np.apply_along_axis(check_out_of_range, 1, X1, x_min = X_min, x_max = X_max)\n",
    "num_outliers = sum(outliers)\n",
    "\n",
    "Y1 = generate_data(X1, dgp) + np.random.normal(size=n1)\n",
    "\n",
    "# PIs = compute_PIs(X,Y,X1,alpha,random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Y)\n",
    "n1 = X1.shape[0]\n",
    "\n",
    "###############################\n",
    "# XBART-GP\n",
    "###############################\n",
    "\n",
    "num_trees = 20\n",
    "num_sweeps = 100\n",
    "burnin = 20\n",
    "tau = np.var(Y) / num_trees\n",
    "theta = 0.1\n",
    "n_min = 20\n",
    "xbart = XBART(num_trees = num_trees, num_sweeps = num_sweeps + burnin, burnin = burnin, tau = tau, sampling_tau = True, n_min = n_min)\n",
    "xbart.fit(X,Y,0)\n",
    "mu_pred = xbart.predict(X1, return_mean = False)\n",
    "mu_pred = mu_pred[:, burnin:] # discard burnin\n",
    "\n",
    "y_pred = pd.DataFrame(mu_pred).transpose().apply(\n",
    "    lambda x: x + xbart.sigma_draws[burnin:,num_trees - 1] * np.random.normal(size=num_sweeps), 0).transpose() \n",
    "xbart_PI =  pd.DataFrame(y_pred).transpose().apply(\n",
    "                lambda x: [np.quantile(x, alpha/2), np.quantile(x, 1 - alpha/2), x.mean()], 0).transpose()\n",
    "xbart_PI.rename(columns = {0: 'lower', 1: 'upper', 2:'pred'}, inplace = True)\n",
    "\n",
    "mu_pred_gp = xbart.predict_gp(X, Y, X1, p_cat = 0, theta = theta, tau = np.var(Y) / num_trees, return_mean=False)\n",
    "mu_pred_gp = mu_pred_gp[:,burnin:]\n",
    "y_pred_gp = pd.DataFrame(mu_pred_gp).transpose().apply(\n",
    "    lambda x: x + xbart.sigma_draws[burnin:,num_trees - 1] * np.random.normal(size=num_sweeps), 0).transpose() \n",
    "xbart_PI_gp =  pd.DataFrame(y_pred_gp).transpose().apply(\n",
    "                lambda x: [np.quantile(x, alpha/2), np.quantile(x, 1 - alpha/2), x.mean()], 0).transpose()\n",
    "xbart_PI_gp.rename(columns = {0: 'lower', 1: 'upper', 2:'pred'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "modified-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Jackknife+ XBART\n",
    "###############################\n",
    "\n",
    "# muh_vals = fit_muh_fun(X,Y,np.r_[X,X1])\n",
    "xbart = XBART(num_trees = num_trees, num_sweeps = num_sweeps + burnin, burnin = burnin, tau = tau, sampling_tau = True)\n",
    "# xbart.fit(X,Y,0)\n",
    "# muh_vals = xbart.predict(np.r_[X,X1], return_mean = True)\n",
    "# resids_naive = np.abs(Y-muh_vals[:n])\n",
    "# muh_vals_testpoint = muh_vals[n:]\n",
    "resids_LOO_xbart = np.zeros(n)\n",
    "resids_LOO_xbart_gp = np.zeros(n)\n",
    "muh_LOO_vals_testpoint_xbart = np.zeros((n,n1))\n",
    "muh_LOO_vals_testpoint_xbart_gp = np.zeros((n, n1))\n",
    "for i in range(n):\n",
    "    # muh_vals_LOO = fit_muh_fun(np.delete(X,i,0),np.delete(Y,i),\\\n",
    "    #                            np.r_[X[i].reshape((1,-1)),X1])\n",
    "    xbart.fit(np.delete(X,i,0),np.delete(Y,i), 0)\n",
    "    muh_vals_LOO = xbart.predict(np.r_[X[i].reshape((1,-1)),X1])\n",
    "    resids_LOO_xbart[i] = np.abs(Y[i] - muh_vals_LOO[0])\n",
    "    muh_LOO_vals_testpoint_xbart[i] = muh_vals_LOO[1:]\n",
    "\n",
    "    muh_vals_LOO_gp = xbart.predict_gp(X, Y, np.r_[X[i].reshape((1,-1)),X1], p_cat = 0, theta = theta, tau = np.var(Y) / num_trees, return_mean=True)\n",
    "    resids_LOO_xbart_gp[i] = np.abs(Y[i] - muh_vals_LOO_gp[0])\n",
    "    muh_LOO_vals_testpoint_xbart_gp[i] = muh_vals_LOO_gp[1:]\n",
    "\n",
    "ind_q = (np.ceil((1-alpha)*(n+1))).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "burning-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.52979792, -2.32795168, -5.10470668, -2.71216746,  3.08581817])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muh_LOO_vals_testpoint_xbart_gp.T.mean(axis = 1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dominant-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.56170744, -1.1180615 , -5.14054906, -4.71900669,  3.00277402])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muh_LOO_vals_testpoint_xbart.T.mean(axis = 1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latin-iraqi",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (257250255.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/01/l9rwq0097m9dz413l3qd0lxm0000gp/T/ipykernel_45847/257250255.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    n_K = np.floor(n/K).astype(int)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " K = 10\n",
    "    n_K = np.floor(n/K).astype(int)\n",
    "    base_inds_to_delete = np.arange(n_K).astype(int)\n",
    "    resids_LKO_xbart = np.zeros(n)\n",
    "    resids_LKO_xbart_gp = np.zeros(n)\n",
    "    muh_LKO_vals_testpoint_xbart = np.zeros((n,n1))\n",
    "    muh_LKO_vals_testpoint_xbart_gp = np.zeros((n, n1))\n",
    "    for i in range(K):\n",
    "        inds_to_delete = (base_inds_to_delete + n_K*i).astype(int)\n",
    "        # muh_vals_LKO = fit_muh_fun(np.delete(X,inds_to_delete,0),np.delete(Y,inds_to_delete),\\\n",
    "        #                            np.r_[X[inds_to_delete],X1])\n",
    "        xbart.fit(np.delete(X,inds_to_delete,0),np.delete(Y,inds_to_delete),0)\n",
    "        muh_vals_LKO = xbart.predict(np.r_[X[inds_to_delete],X1])\n",
    "        resids_LKO_xbart[inds_to_delete] = np.abs(Y[inds_to_delete] - muh_vals_LKO[:n_K])\n",
    "        for inner_K in range(n_K):\n",
    "            muh_LKO_vals_testpoint_xbart[inds_to_delete[inner_K]] = muh_vals_LKO[n_K:]\n",
    "\n",
    "        muh_vals_LKO_gp = xbart.predict_gp(X, Y, np.r_[X[inds_to_delete],X1], p_cat = 0, theta = theta, tau = np.var(Y) / num_trees, return_mean=True)\n",
    "        resids_LKO_xbart_gp[inds_to_delete] = np.abs(Y[inds_to_delete] - muh_vals_LKO_gp[:n_K])\n",
    "        for inner_K in range(n_K):\n",
    "            muh_LKO_vals_testpoint_xbart_gp[inds_to_delete[inner_K]] = muh_vals_LKO_gp[n_K:]\n",
    "\n",
    "\n",
    "    ind_Kq = (np.ceil((1-alpha)*(n+1))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    " PIs_dict = {'XBART' : xbart_PI,\\\n",
    "                'XBART-GP': xbart_PI_gp,\\\n",
    "                'jackknife+ XBART' : pd.DataFrame(\\\n",
    "                    np.c_[np.sort(muh_LOO_vals_testpoint_xbart.T - resids_LOO_xbart,axis=1).T[-ind_q], \\\n",
    "                        np.sort(muh_LOO_vals_testpoint_xbart.T + resids_LOO_xbart,axis=1).T[ind_q-1],\n",
    "                         muh_LOO_vals_testpoint_xbart.T.mean(axis = 1)],\\\n",
    "                           columns = ['lower','upper', 'pred']),\\\n",
    "                 'jackknife+ XBART-GP' : pd.DataFrame(\\\n",
    "                    np.c_[np.sort(muh_LOO_vals_testpoint_xbart_gp.T - resids_LOO_xbart_gp,axis=1).T[-ind_q], \\\n",
    "                        np.sort(muh_LOO_vals_testpoint_xbart_gp.T + resids_LOO_xbart_gp,axis=1).T[ind_q-1], \n",
    "                         muh_LOO_vals_testpoint_xbart_gp.T.mean(axis = 1)],\\\n",
    "                           columns = ['lower','upper', 'pred']),\\\n",
    "                'CV+ XBART' : pd.DataFrame(\\\n",
    "                    np.c_[np.sort(muh_LKO_vals_testpoint_xbart.T - resids_LKO_xbart,axis=1).T[-ind_Kq], \\\n",
    "                        np.sort(muh_LKO_vals_testpoint_xbart.T + resids_LKO_xbart,axis=1).T[ind_Kq-1],\n",
    "                         muh_LKO_vals_testpoint_xbart.T.mean(axis = 1)],\\\n",
    "                           columns = ['lower','upper', 'pred']),\\\n",
    "                'CV+ XBAR-GP' : pd.DataFrame(\\\n",
    "                    np.c_[np.sort(muh_LKO_vals_testpoint_xbart_gp.T - resids_LKO_xbart_gp,axis=1).T[-ind_Kq], \\\n",
    "                        np.sort(muh_LKO_vals_testpoint_xbart_gp.T + resids_LKO_xbart_gp,axis=1).T[ind_Kq-1],\n",
    "                         muh_LKO_vals_testpoint_xbart_gp.T.mean(axis = 1)],\\\n",
    "                           columns = ['lower','upper', 'pred']),\\\n",
    "                \n",
    "               }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
